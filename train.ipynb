{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rILQ3zfUD688"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import random\n",
    "import json\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hEVbsUW7EVaL"
   },
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "work_path = '/root/python_project/crnn_by_tensorflow2.2.0/'\n",
    "test_path = work_path + 'dataset/test/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6H3YNtjP6EEM"
   },
   "source": [
    "字符集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yrQgZ7aeufA0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "字符数： 5531\n"
     ]
    }
   ],
   "source": [
    "table_path = work_path + \"dataset/table.txt\"\n",
    "json_path = work_path + \"dataset/char.json\"\n",
    "with open(json_path,'r') as f:\n",
    "    chardic = json.load(f)\n",
    "with open(table_path,'w') as fw:\n",
    "    for char in chardic:\n",
    "        fw.write(char+'\\n')\n",
    "num_classes = len(chardic) + 3\n",
    "print('字符数：', num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aOL4nLFOu_Pr"
   },
   "outputs": [],
   "source": [
    "table = tf.lookup.StaticHashTable(tf.lookup.TextFileInitializer(table_path, \n",
    "                                                                tf.string, \n",
    "                                                                tf.lookup.TextFileIndex.WHOLE_LINE, \n",
    "                                                                tf.int64, tf.lookup.TextFileIndex.LINE_NUMBER), num_classes-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LEPtMqGHEr8z"
   },
   "source": [
    "数据预处理方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MZSzUFwhElxH"
   },
   "outputs": [],
   "source": [
    "def preprocess_image(image):\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = tf.image.resize(image, [32, 280])\n",
    "    return image\n",
    "\n",
    "def load_and_preprocess_image(path,label):\n",
    "    image = tf.io.read_file(path)\n",
    "    return preprocess_image(image),label\n",
    "\n",
    "def load_and_preprocess_image_pridict(path):\n",
    "    image = tf.io.read_file(path)\n",
    "    return preprocess_image(image)\n",
    "\n",
    "def decode_label(img,label):\n",
    "    chars = tf.strings.unicode_split(label, \"UTF-8\")\n",
    "    tokens = tf.ragged.map_flat_values(table.lookup, chars)\n",
    "    tokens = tokens.to_sparse()\n",
    "    return img,tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "D4pusZavlsc8"
   },
   "source": [
    "图片路径列表及其对应标签列表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_path(dir_path):\n",
    "    '''\n",
    "    获取图片路径列表,及其标签列表\n",
    "    '''\n",
    "    images  = []\n",
    "    train_all_image_paths = []\n",
    "    train_all_image_labels = []\n",
    "    val_all_image_paths = []\n",
    "    val_all_image_labels = []\n",
    "    for root, dirs, files in os.walk(dir_path):\n",
    "        for file in files:\n",
    "            if '.jpg' in file:\n",
    "                file_path = os.path.join(root, file)\n",
    "                label_path = file_path.replace('.jpg','.txt')\n",
    "                if Path(file_path.replace('.jpg','.txt')).exists():\n",
    "                    with open(label_path) as f:\n",
    "                        label = f.read().strip()\n",
    "                    if len(label)<70 and len(label)>0:\n",
    "                        images.append((file_path, label))\n",
    "    random.shuffle(images)\n",
    "    for image,label in images:\n",
    "        random_num = random.randint(1,80)\n",
    "        if random_num == 5:\n",
    "            val_all_image_paths.append(image)\n",
    "            val_all_image_labels.append(label)\n",
    "        else:\n",
    "            train_all_image_paths.append(image)\n",
    "            train_all_image_labels.append(label)\n",
    "    return train_all_image_paths, train_all_image_labels,val_all_image_paths,val_all_image_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KmIDr1WCExzk"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7628393 7628393 96497 96497\n"
     ]
    }
   ],
   "source": [
    "#训练数据集、验证数据集\n",
    "train_all_image_paths, train_all_image_labels,val_all_image_paths, val_all_image_labels = get_image_path(work_path+'dataset/train/')\n",
    "print(len(train_all_image_paths),len(train_all_image_labels),len(val_all_image_paths),len(val_all_image_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aajzP6u7MjEv"
   },
   "source": [
    "训练：tf.data.Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RhBHiraiMe4r"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 256\n",
    "buffer_size = 10000\n",
    "train_images_num = len(train_all_image_paths)\n",
    "train_steps_per_epoch = train_images_num//BATCH_SIZE\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((train_all_image_paths, train_all_image_labels))\n",
    "train_ds = train_ds.map(load_and_preprocess_image, num_parallel_calls=AUTOTUNE)\n",
    "train_ds = train_ds.shuffle(buffer_size=buffer_size)\n",
    "train_ds = train_ds.repeat()\n",
    "train_ds = train_ds.batch(BATCH_SIZE)\n",
    "train_ds = train_ds.map(decode_label, num_parallel_calls=AUTOTUNE)\n",
    "train_ds = train_ds.apply(tf.data.experimental.ignore_errors())\n",
    "train_ds = train_ds.prefetch(AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aajzP6u7MjEv"
   },
   "source": [
    "验证：tf.data.Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_images_num = len(val_all_image_paths)\n",
    "val_steps_per_epoch = val_images_num//BATCH_SIZE\n",
    "val_ds = tf.data.Dataset.from_tensor_slices((val_all_image_paths, val_all_image_labels))\n",
    "val_ds = val_ds.map(load_and_preprocess_image, num_parallel_calls=AUTOTUNE)\n",
    "val_ds = val_ds.shuffle(buffer_size=buffer_size)\n",
    "val_ds = val_ds.repeat()\n",
    "val_ds = val_ds.batch(BATCH_SIZE)\n",
    "val_ds = val_ds.map(decode_label, num_parallel_calls=AUTOTUNE)\n",
    "val_ds = val_ds.apply(tf.data.experimental.ignore_errors())\n",
    "val_ds = val_ds.prefetch(AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ejQ1Gt03OLG5"
   },
   "source": [
    "模型定义\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DUyAxstwORUf"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "        #tf.keras.layers.Conv2D(filters=64, kernel_size=3, padding='same',activation='relu',input_shape=(32,560,3)),\n",
    "        tf.keras.layers.Conv2D(filters=64, kernel_size=3, padding='same',activation='relu'),\n",
    "        tf.keras.layers.MaxPool2D(pool_size=(2, 2), padding='valid'),\n",
    "        tf.keras.layers.Conv2D(filters=128, kernel_size=3,padding='same',activation='relu'),\n",
    "        tf.keras.layers.MaxPool2D(pool_size=(2, 2), padding='valid'),\n",
    "        tf.keras.layers.Conv2D(filters=256, kernel_size=3, padding='same'),\n",
    "        tf.keras.layers.BatchNormalization(epsilon=1e-05,axis=1, momentum=0.1),\n",
    "        tf.keras.layers.Conv2D(filters=256, kernel_size=3, padding='same'),\n",
    "        tf.keras.layers.ZeroPadding2D(padding=(0, 1)),\n",
    "        tf.keras.layers.MaxPool2D(pool_size=(2, 2), strides=(2, 1), padding='valid'),\n",
    "        tf.keras.layers.Conv2D(filters=512, kernel_size=3, padding='same',activation='relu'),\n",
    "        tf.keras.layers.BatchNormalization(epsilon=1e-05,axis=1, momentum=0.1),\n",
    "        tf.keras.layers.Conv2D(filters=512, kernel_size=3, padding='same',activation='relu'),\n",
    "        tf.keras.layers.ZeroPadding2D(padding=(0, 1)),\n",
    "        tf.keras.layers.MaxPool2D(pool_size=(2, 2), strides=(2, 1), padding='valid'),\n",
    "        tf.keras.layers.Conv2D(filters=512, kernel_size=2, padding='valid', activation='relu'),\n",
    "        tf.keras.layers.BatchNormalization(epsilon=1e-05,axis=1, momentum=0.1),\n",
    "        tf.keras.layers.Reshape((-1, 512)),\n",
    "        tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(units=256, return_sequences=True, use_bias=True,recurrent_activation='sigmoid')),\n",
    "        tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(units=256, return_sequences=True, use_bias=True,recurrent_activation='sigmoid')),\n",
    "        tf.keras.layers.Dense(units=num_classes)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OdNwRyzqsnkX"
   },
   "source": [
    "CTC损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qZt1-7wFrI3N"
   },
   "outputs": [],
   "source": [
    "class CTCLoss(tf.keras.losses.Loss):\n",
    "    def __init__(self, logits_time_major=False, blank_index=-1, \n",
    "                 reduction=tf.keras.losses.Reduction.AUTO, name='ctc_loss'):\n",
    "        super().__init__(reduction=reduction, name=name)\n",
    "        self.logits_time_major = logits_time_major\n",
    "        self.blank_index = blank_index\n",
    "\n",
    "    def call(self, y_true, y_pred):\n",
    "        y_true = tf.cast(y_true, tf.int32)\n",
    "        logit_length = tf.fill([tf.shape(y_pred)[0]], tf.shape(y_pred)[1])\n",
    "        loss = tf.nn.ctc_loss(\n",
    "            labels=y_true,\n",
    "            logits=y_pred,\n",
    "            label_length=None,\n",
    "            logit_length=logit_length,\n",
    "            logits_time_major=self.logits_time_major,\n",
    "            blank_index=self.blank_index\n",
    "            )\n",
    "        return tf.reduce_mean(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yqtm1vw2tHAt"
   },
   "outputs": [],
   "source": [
    "class WordAccuracy(tf.keras.metrics.Metric):\n",
    "    \"\"\"\n",
    "    Calculate the word accuracy between y_true and y_pred.\n",
    "    \"\"\"\n",
    "    def __init__(self, name='word_accuracy', **kwargs):\n",
    "        super().__init__(name=name, **kwargs)\n",
    "        self.total = self.add_weight(name='total', dtype=tf.int32, \n",
    "                                     initializer=tf.zeros_initializer())\n",
    "        self.count = self.add_weight(name='count', dtype=tf.int32, \n",
    "                                     initializer=tf.zeros_initializer())\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        \"\"\"\n",
    "        Maybe have more fast implementation.\n",
    "        \"\"\"\n",
    "        b = tf.shape(y_true)[0]\n",
    "        max_width = tf.maximum(tf.shape(y_true)[1], tf.shape(y_pred)[1])\n",
    "        logit_length = tf.fill([tf.shape(y_pred)[0]], tf.shape(y_pred)[1])        \n",
    "        decoded, _ = tf.nn.ctc_greedy_decoder(\n",
    "            inputs=tf.transpose(y_pred, perm=[1, 0, 2]),\n",
    "            sequence_length=logit_length)\n",
    "        y_true = tf.sparse.reset_shape(y_true, [b, max_width])\n",
    "        y_pred = tf.sparse.reset_shape(decoded[0], [b, max_width])\n",
    "        y_true = tf.sparse.to_dense(y_true, default_value=-1)\n",
    "        y_pred = tf.sparse.to_dense(y_pred, default_value=-1)\n",
    "        y_true = tf.cast(y_true, tf.int32)\n",
    "        y_pred = tf.cast(y_pred, tf.int32)\n",
    "        values = tf.math.reduce_any(tf.math.not_equal(y_true, y_pred), axis=1)\n",
    "        values = tf.cast(values, tf.int32)\n",
    "        values = tf.reduce_sum(values)\n",
    "        self.total.assign_add(b)\n",
    "        self.count.assign_add(b - values)\n",
    "\n",
    "    def result(self):\n",
    "        return self.count / self.total\n",
    "\n",
    "    def reset_states(self):\n",
    "        self.count.assign(0)\n",
    "        self.total.assign(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "加载已保存模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(work_path + 'output/crnn_4.h5', compile=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gpBZnmh0O1uY"
   },
   "source": [
    "模型编译"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Bj3sFrXgO0us"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "              loss=CTCLoss(), metrics=[WordAccuracy()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "errVphyYu3WC"
   },
   "source": [
    "显示使用GPU数量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UasdXV0bu1Z2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0ImnMvZX7Ajn"
   },
   "outputs": [],
   "source": [
    "callbacks = [tf.keras.callbacks.ModelCheckpoint(work_path + 'output/crnn_{epoch}.h5',monitor='val_loss',verbose=1),\n",
    "             tf.keras.callbacks.TensorBoard(log_dir=work_path + \"logs/{}\".format(time.asctime()))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aajzP6u7MjEv"
   },
   "source": [
    "加载模型继续训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 29798 steps, validate for 376 steps\n",
      "Epoch 5/20\n",
      "29797/29798 [============================>.] - ETA: 1s - loss: inf - word_accuracy: 0.6830\n",
      "Epoch 00005: saving model to /root/python_project/jupyter_file/output/crnn_5.h5\n",
      "29798/29798 [==============================] - 52077s 2s/step - loss: inf - word_accuracy: 0.6830 - val_loss: inf - val_word_accuracy: 0.6709\n",
      "Epoch 6/20\n",
      "17138/29798 [================>.............] - ETA: 6:40:14 - loss: inf - word_accuracy: 0.6832\n",
      "Epoch 00006: saving model to /root/python_project/jupyter_file/output/crnn_6.h5\n",
      "17138/29798 [================>.............] - ETA: 6:40:15 - loss: inf - word_accuracy: 0.6832"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-75-84fc1516814a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m           \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m           \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m           workers=8)\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/tf2.2-gpu/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 728\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/anaconda3/envs/tf2.2-gpu/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    325\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2.2-gpu/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    121\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    122\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2.2-gpu/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 86\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2.2-gpu/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_counter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalled_without_tracing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2.2-gpu/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    485\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 487\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    488\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2.2-gpu/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1821\u001b[0m     \u001b[0;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1822\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1823\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1824\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1825\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2.2-gpu/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1139\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1140\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1141\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1143\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2.2-gpu/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1222\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[0;32m-> 1224\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1225\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2.2-gpu/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    512\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/anaconda3/envs/tf2.2-gpu/lib/python3.6/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(train_ds, \n",
    "          epochs=20, \n",
    "          steps_per_epoch=train_steps_per_epoch,\n",
    "          validation_data=val_ds,\n",
    "          validation_steps=val_steps_per_epoch,\n",
    "          initial_epoch=4,\n",
    "          callbacks = callbacks,\n",
    "          workers=8)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyP2Eg6pvevGDGaZ1lOjlih4",
   "collapsed_sections": [],
   "mount_file_id": "1pHFhW9EuX06p63puOUBufLkQUJm6JayS",
   "name": "ocr_dataset.ipynb",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
